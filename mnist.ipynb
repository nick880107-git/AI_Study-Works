{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJwNak4t4CaAyhIlOb5ZBV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nick880107-git/AI_Study-Works/blob/master/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRYYDOS06kf2",
        "outputId": "f95f8a00-a3da-47eb-c903-1ea87e8fcb69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8WO8Be37e25",
        "outputId": "38a9a328-cdad-43ed-8bd4-43e59ea8a35f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(x_train,y_train), (x_test,y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9o3gqwM7kP_",
        "outputId": "3c74f55b-b268-45d4-9b09-f1443087d10c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(x_train[5888])\n",
        "print(\"數字是：\",y_train[5888])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "數字是： 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDKt7L7c8jn8"
      },
      "source": [
        "#改成灰階\n",
        "x_train=x_train.reshape(x_train.shape[0],28,28,1).astype('float32')\n",
        "x_test=x_test.reshape(x_test.shape[0],28,28,1).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJUuQ7GN-CWP"
      },
      "source": [
        "#變成純黑純白\n",
        "x_train=x_train/255\n",
        "x_test=x_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lCFEmkU-KXf"
      },
      "source": [
        "#處理類別資料(Onehot encoding)\n",
        "y_train=np_utils.to_categorical(y_train,10)\n",
        "y_test=np_utils.to_categorical(y_test,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVTl5yNAAppE"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_0Ds3UgA2pF"
      },
      "source": [
        "#宣告model是一個線性模型\n",
        "model=Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZx3GEjGA5jg"
      },
      "source": [
        "#加入卷積層 & 池化層\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3),padding='same',input_shape=(28,28,1),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijLtvUKaBO27"
      },
      "source": [
        "#加入Dropout層，避免Overfitting\n",
        "model.add(Dropout(0.25))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eSEczd4BVZG"
      },
      "source": [
        "#加入Flatten層\n",
        "model.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7GQJBuRCNMp"
      },
      "source": [
        "#加入全連接層\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YaJxmSvCg8H",
        "outputId": "58a12eb6-cbb4-4d6c-c729-aa3a1a3889bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#訓練模型\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(x=x_train,y=y_train,validation_data=(x_test,y_test),epochs=100,batch_size=300,verbose=1)\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:',score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.4052 - accuracy: 0.8758 - val_loss: 0.0774 - val_accuracy: 0.9743\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1166 - accuracy: 0.9655 - val_loss: 0.0497 - val_accuracy: 0.9848\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0852 - accuracy: 0.9742 - val_loss: 0.0389 - val_accuracy: 0.9856\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0677 - accuracy: 0.9798 - val_loss: 0.0323 - val_accuracy: 0.9892\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0602 - accuracy: 0.9818 - val_loss: 0.0275 - val_accuracy: 0.9908\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0546 - accuracy: 0.9836 - val_loss: 0.0280 - val_accuracy: 0.9911\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0461 - accuracy: 0.9858 - val_loss: 0.0277 - val_accuracy: 0.9903\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0457 - accuracy: 0.9861 - val_loss: 0.0253 - val_accuracy: 0.9912\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0397 - accuracy: 0.9879 - val_loss: 0.0228 - val_accuracy: 0.9919\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0380 - accuracy: 0.9882 - val_loss: 0.0245 - val_accuracy: 0.9918\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.0239 - val_accuracy: 0.9921\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.0215 - val_accuracy: 0.9925\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.0239 - val_accuracy: 0.9921\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 0.0221 - val_accuracy: 0.9924\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 0.0234 - val_accuracy: 0.9924\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0259 - accuracy: 0.9918 - val_loss: 0.0237 - val_accuracy: 0.9920\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.0226 - val_accuracy: 0.9926\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.0220 - val_accuracy: 0.9924\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.0245 - val_accuracy: 0.9919\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.0230 - val_accuracy: 0.9932\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.0225 - val_accuracy: 0.9928\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0223 - val_accuracy: 0.9933\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0226 - val_accuracy: 0.9935\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0226 - val_accuracy: 0.9935\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0213 - val_accuracy: 0.9936\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0196 - val_accuracy: 0.9942\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0209 - val_accuracy: 0.9938\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 0.0235 - val_accuracy: 0.9930\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0208 - val_accuracy: 0.9936\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.0193 - val_accuracy: 0.9943\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.0203 - val_accuracy: 0.9940\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0212 - val_accuracy: 0.9940\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.0218 - val_accuracy: 0.9931\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 0.0250 - val_accuracy: 0.9935\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0129 - accuracy: 0.9955 - val_loss: 0.0242 - val_accuracy: 0.9928\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0234 - val_accuracy: 0.9935\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 0.0137 - accuracy: 0.9950 - val_loss: 0.0244 - val_accuracy: 0.9933\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.0203 - val_accuracy: 0.9939\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0218 - val_accuracy: 0.9927\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.0207 - val_accuracy: 0.9939\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0211 - val_accuracy: 0.9942\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0209 - val_accuracy: 0.9942\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.0248 - val_accuracy: 0.9932\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0213 - val_accuracy: 0.9934\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0205 - val_accuracy: 0.9940\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 0.0225 - val_accuracy: 0.9943\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.0215 - val_accuracy: 0.9946\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0212 - val_accuracy: 0.9947\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.0247 - val_accuracy: 0.9932\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0237 - val_accuracy: 0.9937\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.0230 - val_accuracy: 0.9936\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.0227 - val_accuracy: 0.9936\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.0230 - val_accuracy: 0.9941\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0266 - val_accuracy: 0.9936\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0220 - val_accuracy: 0.9943\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.0229 - val_accuracy: 0.9942\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0228 - val_accuracy: 0.9938\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0245 - val_accuracy: 0.9936\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0216 - val_accuracy: 0.9937\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0255 - val_accuracy: 0.9938\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.0255 - val_accuracy: 0.9939\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.0257 - val_accuracy: 0.9939\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0240 - val_accuracy: 0.9939\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0228 - val_accuracy: 0.9937\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0241 - val_accuracy: 0.9935\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0211 - val_accuracy: 0.9946\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0226 - val_accuracy: 0.9936\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0266 - val_accuracy: 0.9941\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0276 - val_accuracy: 0.9943\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0222 - val_accuracy: 0.9940\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0234 - val_accuracy: 0.9942\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0264 - val_accuracy: 0.9933\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0237 - val_accuracy: 0.9941\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.0234 - val_accuracy: 0.9940\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.0225 - val_accuracy: 0.9945\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0243 - val_accuracy: 0.9941\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0234 - val_accuracy: 0.9945\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0253 - val_accuracy: 0.9941\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.0241 - val_accuracy: 0.9937\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0278 - val_accuracy: 0.9937\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0262 - val_accuracy: 0.9939\n",
            "Epoch 82/100\n",
            "51300/60000 [========================>.....] - ETA: 8s - loss: 0.0075 - accuracy: 0.9974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-231166860bf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#訓練模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDSasdIiXGD8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}