{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFN9_wV7kgAk"
      },
      "source": [
        "import pickle   #python版的json套件，可將python資料型態的資料進行匯出/匯入\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "DSWYfcpxm3IJ",
        "outputId": "aa178912-d02b-4859-e89f-d839d343e97f"
      },
      "source": [
        "# 擷取網路上練習的capitals.txt做為資料集\r\n",
        "\r\n",
        "data = pd.read_csv('capitals.txt', delimiter=' ')\r\n",
        "data.columns = ['city1','country1','city2','country2']\r\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city1</th>\n",
              "      <th>country1</th>\n",
              "      <th>city2</th>\n",
              "      <th>country2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Bangkok</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Beijing</td>\n",
              "      <td>China</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Bern</td>\n",
              "      <td>Switzerland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Cairo</td>\n",
              "      <td>Egypt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    city1 country1    city2     country2\n",
              "0  Athens   Greece  Bangkok     Thailand\n",
              "1  Athens   Greece  Beijing        China\n",
              "2  Athens   Greece   Berlin      Germany\n",
              "3  Athens   Greece     Bern  Switzerland\n",
              "4  Athens   Greece    Cairo        Egypt"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luC1OJD_peyi",
        "outputId": "002b2de9-a266-469e-b2ff-0bed250d960b"
      },
      "source": [
        "# 語料庫使用googlenews-vectors\r\n",
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-05 08:26:06--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.90.94\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.90.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 1647046227 (1.5G), 1480026706 (1.4G) remaining [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "   GoogleNews-vecto  13%[++                  ] 213.85M  34.0MB/s               ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "bikm9hR7oJ7k",
        "outputId": "1986a446-7183-494c-e94c-290280906505"
      },
      "source": [
        "# 因為googlenews資料龐大，我們擷取相關的資料來做訓練即可\r\n",
        "# 使用KeyedVectors對語料庫進行處理，將其轉換成向量格式\r\n",
        "import nltk\r\n",
        "from gensim.models import KeyedVectors\r\n",
        "\r\n",
        "embeddings = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary = True)\r\n",
        "f = open('capitals.txt', 'r').read()\r\n",
        "\r\n",
        "# 擷取所需字詞，並以集合(set)形式儲存\r\n",
        "set_words = set(nltk.word_tokenize(f))\r\n",
        "select_words = words = ['king', 'queen', 'oil', 'gas', 'happy', 'sad', 'city', 'town', 'village', 'country', 'continent', 'petroleum', 'joyful']\r\n",
        "for w in select_words:\r\n",
        "    set_words.add(w)\r\n",
        "\r\n",
        "# 定義函式，輸入一語料庫(向量形式)，若其中包含集合中的字詞向量，則存入word_embeddings並回傳\r\n",
        "def get_word_embeddings(embeddings):\r\n",
        "\r\n",
        "    word_embeddings = {}\r\n",
        "    for word in embeddings.vocab:\r\n",
        "        if word in set_words:\r\n",
        "            word_embeddings[word] = embeddings[word]\r\n",
        "    return word_embeddings\r\n",
        "\r\n",
        "word_embeddings = get_word_embeddings(embeddings)\r\n",
        "print(len(word_embeddings))\r\n",
        "pickle.dump( word_embeddings, open( \"word_embeddings_subset.p\", \"wb\" ) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9863243ecd3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'capitals.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mset_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0mignore_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mignore_extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './GoogleNews-vectors-negative300.bin'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWdFvKNTy10j"
      },
      "source": [
        "# 讀取前面匯出的word_embeddings\r\n",
        "word_embeddings = pickle.load(open(\"word_embeddings_subset.p\", \"rb\"))\r\n",
        "len(word_embeddings)  # there should be 243 words that will be used in this assignment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D27Ndpon1CXP"
      },
      "source": [
        "# 製作prediction函式\r\n",
        "輸入city1、country1與city2，並根據city1←→country1間的關係推測與city2有關的country"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjU-0WCzzvCJ"
      },
      "source": [
        "使用餘弦判斷兩個向量的相似度\r\n",
        "\r\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3LFhs26zheB"
      },
      "source": [
        "def cosine_similarity(A, B):\r\n",
        "    '''\r\n",
        "    Input:\r\n",
        "        A: a numpy array which corresponds to a word vector\r\n",
        "        B: A numpy array which corresponds to a word vector\r\n",
        "    Output:\r\n",
        "        cos: numerical number representing the cosine similarity between A and B.\r\n",
        "    '''\r\n",
        "\r\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\r\n",
        "    \r\n",
        "    dot = np.dot(A,B)\r\n",
        "    norma = np.sqrt(np.dot(A,A))\r\n",
        "    normb = np.sqrt(np.dot(B,B))\r\n",
        "    cos = dot / (norma*normb)\r\n",
        "\r\n",
        "    ### END CODE HERE ###\r\n",
        "    return cos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zubOvo-0KJq"
      },
      "source": [
        "使用歐式距離判斷兩個向量的相似度\r\n",
        "\r\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pj5FOdB0MEx"
      },
      "source": [
        "def euclidean(A, B):\r\n",
        "    \"\"\"\r\n",
        "    Input:\r\n",
        "        A: a numpy array which corresponds to a word vector\r\n",
        "        B: A numpy array which corresponds to a word vector\r\n",
        "    Output:\r\n",
        "        d: numerical number representing the Euclidean distance between A and B.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\r\n",
        "\r\n",
        "    # euclidean distance\r\n",
        "\r\n",
        "    d = np.linalg.norm(A-B)\r\n",
        "\r\n",
        "    ### END CODE HERE ###\r\n",
        "\r\n",
        "    return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Saa5W2_01JCc"
      },
      "source": [
        "def get_country(city1, country1, city2, embeddings):\r\n",
        "    \"\"\"\r\n",
        "    Input:\r\n",
        "        city1: a string (the capital city of country1)\r\n",
        "        country1: a string (the country of capital1)\r\n",
        "        city2: a string (the capital city of country2)\r\n",
        "        embeddings: a dictionary where the keys are words and values are their embeddings\r\n",
        "    Output:\r\n",
        "        countries: a dictionary with the most likely country and its similarity score\r\n",
        "    \"\"\"\r\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\r\n",
        "\r\n",
        "    # 先將city1,country1,city2存入一個集合\r\n",
        "    group = set((city1, country1, city2))\r\n",
        "\r\n",
        "    # 取得其在我們word_embedding的向量\r\n",
        "    city1_emb = word_embeddings[city1]\r\n",
        "    country1_emb = word_embeddings[country1]\r\n",
        "    city2_emb = word_embeddings[city2]\r\n",
        "\r\n",
        "    # 計算country2的理想向量\r\n",
        "    # 理論上 city1 - country1 = city2 - country2\r\n",
        "    # 所以country2 = country1 - city1 + city2\r\n",
        "    vec = country1_emb - city1_emb + city2_emb\r\n",
        "\r\n",
        "    # 初始化相似度，盡可能找到相似度為1的\r\n",
        "    similarity = -1\r\n",
        "\r\n",
        "    # 初始化country2\r\n",
        "    country = ''\r\n",
        "\r\n",
        "    # 從我們的county名單中逐一檢查其向量與city2的相似度\r\n",
        "    for word in embeddings.keys():\r\n",
        "\r\n",
        "        # 找輸入集合外的資料\r\n",
        "        if word not in group:\r\n",
        "\r\n",
        "            # 取得該country在word_embedding的向量\r\n",
        "            word_emb = word_embeddings[word]\r\n",
        "\r\n",
        "            # 利用餘弦計算兩向量的相似程度\r\n",
        "            cur_similarity = cosine_similarity(vec,word_emb)\r\n",
        "\r\n",
        "            # 更新最接近(餘弦值最大，最接近1)的country\r\n",
        "            if cur_similarity > similarity:\r\n",
        "\r\n",
        "                # update the similarity to the new, better similarity\r\n",
        "                similarity = cur_similarity\r\n",
        "\r\n",
        "                # store the country as a tuple, which contains the word and the similarity\r\n",
        "                country = (word, similarity)\r\n",
        "\r\n",
        "    ### END CODE HERE ###\r\n",
        "\r\n",
        "    return country"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ3M0vo96H1a"
      },
      "source": [
        "# 計算準確度\r\n",
        "# 輸入我們製作的word_embeddings,以及capitals.txt的資料(pandas dataframe形式)\r\n",
        "# 比對每一列(row)，取出其city1,country1,city2,country2，並呼叫get_country\r\n",
        "# 計算預測正確的結果數，並回傳準確度\r\n",
        "def get_accuracy(word_embeddings, data):\r\n",
        "    '''\r\n",
        "    Input:\r\n",
        "        word_embeddings: a dictionary where the key is a word and the value is its embedding\r\n",
        "        data: a pandas dataframe containing all the country and capital city pairs\r\n",
        "    \r\n",
        "    Output:\r\n",
        "        accuracy: the accuracy of the model\r\n",
        "    '''\r\n",
        "\r\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\r\n",
        "    # initialize num correct to zero\r\n",
        "    num_correct = 0\r\n",
        "\r\n",
        "    # 透過data.iterrows讀取每一row資料\r\n",
        "    # 如果要進入這整列資料的某一格，就row[column_name]\r\n",
        "    for i, row in data.iterrows():\r\n",
        "\r\n",
        "        # get city1\r\n",
        "        city1 = row['city1']\r\n",
        "\r\n",
        "        # get country1\r\n",
        "        country1 = row['country1']\r\n",
        "\r\n",
        "        # get city2\r\n",
        "        city2 =  row['city2']\r\n",
        "\r\n",
        "        # get country2\r\n",
        "        country2 = row['country2']\r\n",
        "\r\n",
        "        # use get_country to find the predicted country2\r\n",
        "        predicted_country2, _ = get_country(city1,country1,city2,word_embeddings)\r\n",
        "\r\n",
        "        # if the predicted country2 is the same as the actual country2...\r\n",
        "        if predicted_country2 == country2:\r\n",
        "            # increment the number of correct by 1\r\n",
        "            num_correct += 1\r\n",
        "\r\n",
        "    # get the number of rows in the data dataframe (length of dataframe)\r\n",
        "    m = len(data)\r\n",
        "\r\n",
        "    # calculate the accuracy by dividing the number correct by m\r\n",
        "    accuracy = num_correct/m\r\n",
        "\r\n",
        "    ### END CODE HERE ###\r\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEjjkBqWiZhl"
      },
      "source": [
        "# 利用PCA降維\r\n",
        "PCA(主成分分析)，是一種透過線性方法，將資料投影到一vector w，使所有資料z的奇異度(Variance)最大。\r\n",
        "\r\n",
        "舉例來說，原本二維的資料，若找一個vector w，使所有資料投影其上，那這些資料就會變成一維(相對於vector w )，如此便可達到降維的目的。\r\n",
        "\r\n",
        "然而我們不希望降維後資料間的差異消失(投影完所有資料都擠在一起就無法區別了)，因此這個w必須要盡可能讓投影得到資料z的奇異度(變異數)最大，在降維的同時仍保持資料的特性\r\n",
        "\r\n",
        "利用此方式，便可將原本的資料投影到任意的維度，但須注意在求每一維度的w時需滿足：\r\n",
        "Wm * Wn = 1 \r\n",
        "(新維度的w和前一個求出的w內積為0，不設此限制的話你每次求到的最大值w就都一樣了)\r\n",
        "\r\n",
        "要求這些w，相當於求原資料covariance matrix的eigenvector，其中eigenvector有最大的eigenvalue\r\n",
        "\r\n",
        "\r\n",
        "*   covariance matrix是根據PCA定義(求Max Var(z))中整理出的一部分\r\n",
        "*   eigenvector及eigenvalue則可理解為目標矩陣中，不因投影or座標軸改變使得其向量脫離原向量方向的vector & 伸縮的長度\r\n",
        "*   用白話文翻譯就是，目標矩陣存在一個「特徵」(eigenvector)，而這個特徵在任何座標軸只會有長度上的差異(eigenvalue)，而不影響特徵本身(不發生旋轉或是變形)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgGF_4ZWjyN4"
      },
      "source": [
        "def compute_pca(X, n_components=2):\r\n",
        "    \"\"\"\r\n",
        "    Input:\r\n",
        "        X: 我們的word vector\r\n",
        "        n_components: 要降成幾維\r\n",
        "    Output:\r\n",
        "        X_reduced: 降成目標維度的資料\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\r\n",
        "    # 求Var(X) (以矩陣表示)\r\n",
        "    X_demeaned = X - np.mean(X,axis=0)\r\n",
        "    print('X_demeaned.shape: ',X_demeaned.shape)\r\n",
        "    \r\n",
        "    # 計算Cov(X)\r\n",
        "    covariance_matrix = np.cov(X_demeaned, rowvar=False)\r\n",
        "\r\n",
        "    # 計算eigenvector、eigenvalue\r\n",
        "    eigen_vals, eigen_vecs = np.linalg.eigh(covariance_matrix, UPLO='L')\r\n",
        "    \r\n",
        "    # 由大到小排序eigenvalue的index，再用這些index排序出由大到小的eigenvalue\r\n",
        "    idx_sorted = np.argsort(eigen_vals)  \r\n",
        "    idx_sorted_decreasing = idx_sorted[::-1]\r\n",
        "    eigen_vals_sorted = eigen_vals[idx_sorted_decreasing]\r\n",
        "\r\n",
        "    # 同理，利用這些index排序出對應順序的eigenvector\r\n",
        "    eigen_vecs_sorted = eigen_vecs[:,idx_sorted_decreasing]\r\n",
        "\r\n",
        "    # 根據你要的維度數，選擇前n個eigenvector\r\n",
        "    eigen_vecs_subset = eigen_vecs_sorted[:,0:n_components]\r\n",
        "\r\n",
        "    # 將降維的結果回傳\r\n",
        "    # Z = wx\r\n",
        "    X_reduced = np.dot(eigen_vecs_subset.transpose(),X_demeaned.transpose()).transpose()\r\n",
        "\r\n",
        "    ### END CODE HERE ###\r\n",
        "\r\n",
        "    return X_reduced"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}